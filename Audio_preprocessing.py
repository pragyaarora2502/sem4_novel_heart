{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":923,"sourceType":"datasetVersion","datasetId":453}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport librosa\nimport os\nimport fnmatch\nimport json\n\nn_mfcc = 30\n\n# Function to shift the data along the time axis\ndef manipulate(data, sr, time, direction):\n    shift = int(sr * time)\n    if direction == 'right':\n        shift = -shift\n    aug_data = np.roll(data, shift)\n    if shift > 0:\n        aug_data[:shift] = 0\n    else:\n        aug_data[shift:] = 0\n    return aug_data\n\n# Function to chop initial and end parts of the audio file\ndef crop(data, sr, time):\n    data = manipulate(data, sr, time, 'right')\n    data = manipulate(data, sr, time * 2, 'left')\n    data = manipulate(data, sr, time, 'right')\n    return data\n\n# Function to create 2 different data frames\n# 1. Dataframe containing only MFCCs\n# 2. Dataframe containing mean values of MFCCs along with other audio features\ndef create_df(folders, columns, types, audio_clip=3, n_mfcc=20):\n    features = []\n    mfccs = {\n        'mfcc': [],\n        'type': []\n    }\n    index = 0\n    for folder in folders:\n        for name in types:\n            files = fnmatch.filter(os.listdir(folder), name)\n            label = name.split(\"*\")[0]\n            for file in files:\n                x, sr = librosa.load(folder + file, sr=22050)\n                x = crop(x, sr, 0.3)\n                duration = librosa.get_duration(y=x, sr=sr)\n                time = int(duration) * sr\n                clip = audio_clip\n                for i in range(0, time + 1 - sr * clip, sr * clip):\n                    # get MFCCs\n                    mfcc = librosa.feature.mfcc(y=x[i:i + sr * clip], sr=sr, n_mfcc=n_mfcc)\n                    mfccs['mfcc'].append(mfcc.T.tolist())\n                    mfccs['type'].append(label)\n                    features.append([np.mean(m) for m in mfcc])\n                    features[index].append(sum(librosa.zero_crossings(x[i:i + sr * 3], pad=False)))\n                    features[index].append(np.mean(librosa.feature.spectral_centroid(y=x[i:i + sr * 3], sr=sr)))\n                    features[index].append(np.mean(librosa.feature.spectral_rolloff(y=x[i:i + sr * 3], sr=sr)))\n                    features[index].append(np.mean(librosa.feature.chroma_stft(y=x[i:i + sr * 3], sr=sr)))\n                    features[index].append(label)\n                    index += 1\n    return pd.DataFrame(features, columns=columns), mfccs\n\n# Similar function as above but doesn't split the audio clips\ndef create_df_without_clips(folders, columns, types, n_mfcc=20):\n    features = []\n    mfccs = {\n        'mfcc': [],\n        'type': []\n    }\n    index = 0\n    for folder in folders:\n        for name in types:\n            files = fnmatch.filter(os.listdir(folder), name)\n            label = name.split(\"*\")[0]\n            for file in files:\n                x, sr = librosa.load(folder + file, sr=22050)\n                x = crop(x, sr, 0.3)\n                mfcc = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=n_mfcc)\n                mfccs['mfcc'].append(mfcc.T.tolist())\n                mfccs['type'].append(label)\n                features.append([np.mean(m) for m in mfcc])\n                features[index].append(sum(librosa.zero_crossings(y=x, pad=False)))\n                features[index].append(np.mean(librosa.feature.spectral_centroid(y=x, sr=sr)))\n                features[index].append(np.mean(librosa.feature.spectral_rolloff(y=x, sr=sr)))\n                features[index].append(np.mean(librosa.feature.chroma_stft(y=x, sr=sr)))\n                features[index].append(label)\n                index += 1\n    return pd.DataFrame(features, columns=columns), mfccs\n\n# Generate the column names\ncolumns = ['mfcc_' + str(i) for i in range(n_mfcc)]\nfor feature in ['zero', 'centroid', 'rolloff', 'chroma', 'type']:\n    columns.append(feature)\nprint(\"Successfully created the columns\")\n\n# Extract all types of heartbeat sounds\ntypes = ['normal*.wav', 'artifact*.wav', 'murmur*.wav', 'extrahls*.wav', 'extrastole*.wav']\nprint(\"Successfully identified all the types of heartbeat sounds\")\n\n# Folder names\nfolders = ['/kaggle/input/heartbeat-sounds/set_a/', '/kaggle/input/heartbeat-sounds/set_b/']\n\n# Create the required dataframes\nprint(\"Started reading and extracting audio features without clipping\")\ndata_without_clips, mfcc_without_clips = create_df_without_clips(folders, columns, types, n_mfcc=30)\nprint(\"Successfully completed reading and extracting audio features without clipping\")\n\nprint(\"Started reading and extracting audio features with clipping\")\ndata, mfcc = create_df(folders, columns, types, n_mfcc=30, audio_clip=3)\nprint(\"Successfully completed reading and extracting audio features with clipping\")\n\n# Write data to files\ndata.to_csv(\"Features.csv\")\nprint(\"Successfully written features to Features.csv file\")\nwith open(\"MFCC.json\", 'w') as fp:\n    json.dump(mfcc, fp, indent=4)\nprint(\"Successfully written mfccs into MFCC.json file\")\n\ndata_without_clips.to_csv(\"Features_without_clips.csv\")\nprint(\"Successfully written features to Features_without_clips.csv file\")\n\nwith open(\"MFCC_without_clips.json\", 'w') as fp:\n    json.dump(mfcc_without_clips, fp, indent=4)\nprint(\"Successfully written mfccs into MFCC_without_clips.json file\")\n\nprint(\"Successfully completed all steps!!!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:56:24.080249Z","iopub.execute_input":"2024-05-30T13:56:24.080717Z","iopub.status.idle":"2024-05-30T14:00:03.741686Z","shell.execute_reply.started":"2024-05-30T13:56:24.080686Z","shell.execute_reply":"2024-05-30T14:00:03.740405Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Successfully created the columns\nSuccessfully identified all the types of heartbeat sounds\nStarted reading and extracting audio features without clipping\nSuccessfully completed reading and extracting audio features without clipping\nStarted reading and extracting audio features with clipping\nSuccessfully completed reading and extracting audio features with clipping\nSuccessfully written features to Features.csv file\nSuccessfully written mfccs into MFCC.json file\nSuccessfully written features to Features_without_clips.csv file\nSuccessfully written mfccs into MFCC_without_clips.json file\nSuccessfully completed all steps!!!\n","output_type":"stream"}]}]}